name: Test Custom GPT

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  test-custom-gpt:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      OPENAI_MODEL_ID: ${{ secrets.OPENAI_MODEL_ID || 'g-68fb932716ac8191abf323ea80f99a7a' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run unit tests
        run: pytest tests/test_runner.py -v --tb=short --junit-xml=test-results.xml
        continue-on-error: true

      - name: Generate test report
        if: always()
        run: |
          python scripts/generate_test_report.py tests/output test-results.xml > TEST_REPORT.md
          cat TEST_REPORT.md

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            TEST_REPORT.md
            test-results.xml
            tests/output/

      - name: Comment PR with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('TEST_REPORT.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

  test-summary:
    runs-on: ubuntu-latest
    needs: test-custom-gpt
    if: always()

    steps:
      - name: Download results
        uses: actions/download-artifact@v4
        with:
          name: test-results

      - name: Display summary
        run: |
          echo "## Test Execution Summary"
          if [ -f TEST_REPORT.md ]; then
            cat TEST_REPORT.md
          fi

      - name: Determine job status
        run: |
          if [ "${{ needs.test-custom-gpt.result }}" = "failure" ]; then
            echo "Tests failed!"
            exit 1
          fi
          echo "Tests passed!"
