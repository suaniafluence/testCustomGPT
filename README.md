# Custom GPT RTF Converter - Testing Framework

Une infrastructure de test complÃ¨te et automatisÃ©e pour un Assistant OpenAI spÃ©cialisÃ© en conversion de texte vers le format RTF (Rich Text Format).

## Vue d'ensemble

Ce projet fournit un **cadre de test professionnel** pour valider la gÃ©nÃ©ration de documents RTF par un Assistant OpenAI. Il inclut :

- âœ… **14 tests automatisÃ©s** (Golden, Robustness, Format Validation)
- ğŸ¤– **Assistant OpenAI personnalisÃ©** pour la conversion RTF
- ğŸ“Š **CI/CD GitHub Actions** pour l'exÃ©cution automatique
- ğŸ“ˆ **Rapports de test** en Markdown
- ğŸ” **Validation RTF** stricte (structure, format, caractÃ¨res spÃ©ciaux)

## Architecture

### Structure du Projet

```
testCustomGPT/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_runner.py          # Suite de tests (14 tests, 300+ lignes)
â”‚   â”œâ”€â”€ input/                  # Fichiers d'entrÃ©e (samples)
â”‚   â”‚   â”œâ”€â”€ sample1.txt         # Test: Rapport mensuel
â”‚   â”‚   â””â”€â”€ sample2.txt         # Test: Guide d'utilisation
â”‚   â”œâ”€â”€ expected/               # Sorties de rÃ©fÃ©rence
â”‚   â”‚   â”œâ”€â”€ sample1_expected.rtf
â”‚   â”‚   â””â”€â”€ sample2_expected.rtf
â”‚   â””â”€â”€ output/                 # Sorties gÃ©nÃ©rÃ©es (auto-crÃ©Ã©)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_assistant.py     # CrÃ©e l'Assistant OpenAI
â”‚   â”œâ”€â”€ update_assistant.py     # Met Ã  jour le prompt
â”‚   â”œâ”€â”€ generate_test_report.py # GÃ©nÃ¨re rapports Markdown
â”‚   â””â”€â”€ debug_*.py              # Scripts de debugging
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ test-custom-gpt.yml     # Pipeline GitHub Actions
â”‚
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ .env.example                # ModÃ¨le de configuration
â”œâ”€â”€ .gitignore                  # Fichiers ignorÃ©s
â”œâ”€â”€ TESTING.md                  # Guide de test dÃ©taillÃ©
â”œâ”€â”€ QUICK_REFERENCE.md          # Aide-mÃ©moire
â””â”€â”€ README.md                   # Ce fichier
```

---

## Installation & Configuration

### 1ï¸âƒ£ PrÃ©requis

- Python 3.10+
- ClÃ© API OpenAI avec accÃ¨s aux Assistants
- Git

### 2ï¸âƒ£ Installation

```bash
# Cloner le dÃ©pÃ´t
git clone <repo-url>
cd testCustomGPT

# CrÃ©er un environnement virtuel
python -m venv venv_test

# Activer (Windows)
venv_test\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configuration

**CrÃ©er le fichier `.env` Ã  la racine :**

```bash
# Copier le modÃ¨le
copy .env.example .env
```

**Ã‰diter `.env` avec tes credentials :**

```env
OPENAI_API_KEY=sk-proj-xxx...
OPENAI_ASSISTANT_ID=asst_xxx...
```

> âš ï¸ Le `.env` est ignorÃ© par Git (sÃ©curitÃ©). Ne jamais committer les clÃ©s API.

---

## Fonctionnement

### Assistant OpenAI

L'Assistant est un **GPT-4 Turbo** spÃ©cialisÃ© en conversion RTF. Il :

1. ReÃ§oit du texte structurÃ© en entrÃ©e
2. GÃ©nÃ¨re un document RTF **valide** et **bien formatÃ©**
3. GÃ¨re les caractÃ¨res spÃ©ciaux (accents, symboles)
4. Applique la hiÃ©rarchie des titres et sections

**Prompt systÃ¨me :**
```
Tu es un expert en conversion de texte vers le format RTF.
Retourne UNIQUEMENT du code RTF valide avec structure complÃ¨te:
- Headers: {\\rtf1\\ansi...}
- FontTable et ColorTable obligatoires
- CaractÃ¨res accentuÃ©s supportÃ©s
- Formatage avec \\b pour gras, \\par pour paragraphes
```

---

## Tests

### Vue d'ensemble des 14 tests

| CatÃ©gorie | Nombre | Objectif |
|-----------|--------|----------|
| RTF Validation | 3 | Valider structure RTF |
| Golden Tests | 6 | Comparer output vs rÃ©fÃ©rence |
| Robustness | 4 | Tester stabilitÃ© & cas limites |
| Integration | 2 | Pipeline end-to-end |

### 1. RTF Validation Tests (3 tests)

Valide la structure RTF elle-mÃªme :

```python
class TestRTFValidation:
    def test_rtf_header_present(self):
        """RTF doit commencer par {\\rtf1\\ansi"""
        assert content.startswith("{\\rtf")

    def test_rtf_unbalanced_braces(self):
        """Accolades doivent Ãªtre Ã©quilibrÃ©es"""
        brace_count = content.count('{') - content.count('}')
        assert brace_count == 0

    def test_rtf_empty_content(self):
        """Contenu vide doit Ãªtre rejetÃ©"""
        assert not RTFValidator.is_valid_rtf("")
```

### 2. Golden Tests (6 tests)

Comparaison input â†’ output vs rÃ©fÃ©rence attendue :

```python
@pytest.mark.parametrize("sample", ["sample1", "sample2"])
class TestGoldenTests:
    def test_rtf_format_validity(self, sample):
        # 1. Appelle l'Assistant avec le sample
        # 2. Valide la structure RTF
        # 3. Sauvegarde pour inspection

    def test_content_matches_expected(self, sample):
        # 1. Extrait le texte visible de l'output
        # 2. Normalise et compare avec rÃ©fÃ©rence
        # 3. TolerÃ¢ncia: 85% similaritÃ© minimum

    def test_no_rtf_corruption(self, sample):
        # 1. VÃ©rifie les Ã©lÃ©ments RTF essentiels
        # 2. \\par, {\\rtf, etc.
```

**ParamÃ©trage automatique :** 3 tests Ã— 2 samples = 6 exÃ©cutions

### 3. Robustness Tests (4 tests)

Teste la stabilitÃ© et les cas spÃ©ciaux :

```python
class TestRobustness:
    @pytest.mark.parametrize("variation", ["sample1.txt", "sample1.txt"])
    def test_consistent_output_format(self, variation):
        # Appels multiples, mÃªme input = output valide

    def test_handles_special_characters(self):
        # "CafÃ©, naÃ¯ve, Â£500, Â© 2025"
        # Doit gÃ©nÃ©rer du RTF valide malgrÃ© caractÃ¨res spÃ©ciaux

    def test_parameter_variations(self):
        # Tests diffÃ©rentes variations du prompt
```

### 4. Integration Tests (2 tests)

Pipeline completo :

```python
class TestIntegration:
    def test_full_pipeline(self):
        # input â†’ API call â†’ validation â†’ comparison
        # Test complet du flux de bout en bout

    def test_report_generation(self):
        # GÃ©nÃ¨re et valide le rapport de test
```

---

## Comment Ã‡a Marche

### Flow API Assistant

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Test appelle CustomGPTTester.call()    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. CrÃ©e un Thread                      â”‚
â”‚     client.beta.threads.create()        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Ajoute le message                   â”‚
â”‚     client.beta.threads.messages.create â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Lance l'Assistant                   â”‚
â”‚     client.beta.threads.runs.create()   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Attend la complÃ©tude (polling)      â”‚
â”‚     while run.status != "completed":    â”‚
â”‚         time.sleep(0.5)                 â”‚
â”‚         run = ...retrieve()             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. RÃ©cupÃ¨re les messages               â”‚
â”‚     client.beta.threads.messages.list() â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Extrait la rÃ©ponse RTF              â”‚
â”‚     msg.content[0].text.value           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Retourne le RTF                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Extraction du texte RTF

**Structure SDK OpenAI :**

```
Message
â”œâ”€â”€ role: "assistant"
â”œâ”€â”€ content: [TextContentBlock]
â”‚   â””â”€â”€ [0]:
â”‚       â”œâ”€â”€ type: "text"
â”‚       â””â”€â”€ text: Text object
â”‚           â””â”€â”€ value: "{\\rtf1..." â† Le RTF rÃ©el !
```

**Code d'extraction :**

```python
def call_custom_gpt(prompt: str) -> str:
    # ... appels API ...

    messages = client.beta.threads.messages.list(thread_id=...)
    for msg in messages.data:
        if msg.role == "assistant":
            content_block = msg.content[0]  # TextContentBlock
            text_obj = content_block.text    # Text object
            return text_obj.value            # ChaÃ®ne RTF rÃ©elle
```

### Validation RTF

La classe `RTFValidator` vÃ©rifie :

```python
class RTFValidator:
    @staticmethod
    def is_valid_rtf(content: str) -> Tuple[bool, str]:
        # 1. Non-vide ?
        if not content.strip():
            return False, "Empty content"

        # 2. En-tÃªte RTF ?
        if not content.startswith("{\\rtf"):
            return False, "Missing RTF header"

        # 3. Braces Ã©quilibrÃ©es ?
        brace_count = 0
        for char in content:
            brace_count += 1 if char == '{' else -1 if char == '}' else 0
            if brace_count < 0:
                return False, "Unbalanced braces"

        if brace_count != 0:
            return False, f"Unbalanced (diff: {brace_count})"

        # 4. Ã‰lÃ©ments essentiels ?
        if "\\ansi" not in content:
            return False, "Missing character set"

        return True, "Valid RTF"
```

### Normalisation de texte

Pour comparer avec tolÃ©rance (85% similaritÃ©) :

```python
class TextNormalizer:
    @staticmethod
    def normalize(text: str) -> str:
        # Minuscules
        text = text.lower()
        # Espacements
        text = re.sub(r"\s+", " ", text).strip()
        # CaractÃ¨res spÃ©ciaux
        text = text.replace("â€”", "-").replace(""", '"')
        return text

    @staticmethod
    def assert_normalized_equal(actual, expected, tolerance=0.85):
        norm_actual = normalize(actual)
        norm_expected = normalize(expected)

        # Compare les mots
        actual_words = set(norm_actual.split())
        expected_words = set(norm_expected.split())

        matching = len(actual_words & expected_words)
        similarity = matching / len(expected_words)

        if similarity < tolerance:
            raise AssertionError(
                f"Similarity {similarity:.0%} < {tolerance:.0%}"
            )
```

---

## Utilisation

### Lancer les tests

```bash
# Tous les tests
pytest tests/test_runner.py -v

# Seulement RTF validation
pytest tests/test_runner.py::TestRTFValidation -v

# Golden tests pour sample1
pytest tests/test_runner.py::TestGoldenTests[sample1] -v

# Test spÃ©cifique
pytest tests/test_runner.py::TestGoldenTests::test_rtf_format_validity[sample1] -v

# ArrÃªter au premier Ã©chec
pytest tests/test_runner.py -x

# Avec couverture
pytest tests/test_runner.py --cov=tests --cov-report=html
```

### GÃ©nÃ©rer un rapport

```bash
# XML pour CI/CD
pytest tests/test_runner.py --junit-xml=test-results.xml

# Markdown report
python scripts/generate_test_report.py tests/output test-results.xml > TEST_REPORT.md

# Afficher
cat TEST_REPORT.md
```

---

## Scripts Disponibles

### create_assistant.py
CrÃ©e un nouvel Assistant OpenAI

```bash
python scripts/create_assistant.py
```

### update_assistant.py
Met Ã  jour le prompt systÃ¨me

```bash
python scripts/update_assistant.py
```

### generate_test_report.py
GÃ©nÃ¨re rapport Markdown

```bash
python scripts/generate_test_report.py <output_dir> [junit_xml_file]
```

### Debug Scripts
```bash
python scripts/test_assistant_output.py    # Inspecte rÃ©ponse brute
python scripts/debug_text_object.py        # Structure objet
python scripts/debug_output.py             # Type de sortie
```

---

## GitHub Actions

### Configuration

Fichier : `.github/workflows/test-custom-gpt.yml`

**Triggers :**
- Push sur `main` ou `develop`
- Pull requests vers `main`
- Schedule journalier (2 AM UTC)

**Ã‰tapes :**
1. Checkout code
2. Setup Python 3.11
3. Install dependencies
4. Run tests (14/14)
5. Generate report
6. Upload artifacts
7. Comment on PR

### Secrets requis

Dans GitHub â†’ Settings â†’ Secrets â†’ New repository secret :

```
OPENAI_API_KEY        = sk-proj-xxx...
OPENAI_ASSISTANT_ID   = asst_xxx...
```

---

## Ajouter des Tests

### CrÃ©er un nouveau cas

**1. Input file :**
```
tests/input/sample3.txt
```

**2. Reference output :**
```
tests/expected/sample3_expected.rtf
```

**3. Update parametrize :**
```python
@pytest.mark.parametrize("sample", ["sample1", "sample2", "sample3"])
class TestGoldenTests:
    # Tests s'exÃ©cutent automatiquement pour sample3
```

**4. Run :**
```bash
pytest tests/test_runner.py::TestGoldenTests[sample3] -v
```

---

## DÃ©pannage

### âŒ OPENAI_API_KEY not found
```bash
cp .env.example .env
# Ã‰diter .env avec tes credentials
```

### âŒ RTF validation failed
```bash
# VÃ©rifier/mettre Ã  jour le prompt
python scripts/update_assistant.py

# Afficher output gÃ©nÃ©rÃ©
cat tests/output/sample1_output.rtf
```

### âŒ Text similarity too low
```bash
# VÃ©rifier la rÃ©fÃ©rence expected
# Ou ajuster tolerance dans test_runner.py
TextNormalizer.assert_normalized_equal(actual, expected, tolerance=0.80)
```

### âŒ Timeout aprÃ¨s 60s
```python
# Augmenter timeout dans test_runner.py:127
timeout = 120  # au lieu de 60
```

---

## Performance

| MÃ©trique | Valeur |
|----------|--------|
| Nombre de tests | 14 |
| DurÃ©e moyenne | 2-3 minutes |
| Couverture | Format, contenu, robustesse |
| Timeout par appel | 60 secondes |
| SimilaritÃ© minimum | 85% |

---

## Ressources

- **TESTING.md** - Guide complet (454 lignes)
- **QUICK_REFERENCE.md** - Aide-mÃ©moire
- **test_runner.py** - ImplÃ©mentation complÃ¨te (300+ lignes)
- [OpenAI Assistants API](https://platform.openai.com/docs/assistants)
- [pytest Documentation](https://docs.pytest.org/)

---

## Licence

CrÃ©Ã© avec [Claude Code](https://claude.com/claude-code)

---

## Support

Pour questions ou problÃ¨mes :

1. **Consulter la doc**
   - TESTING.md (guide dÃ©taillÃ©)
   - QUICK_REFERENCE.md (commandes)

2. **Checker les logs**
   - tests/output/ (outputs gÃ©nÃ©rÃ©s)
   - Dernier run pytest

3. **Lancer debug**
   - `python scripts/test_assistant_output.py`
   - `python scripts/debug_text_object.py`

---

**Statut:** âœ… Production Ready

Tous les tests passent (14/14), infrastructure documentÃ©e et automatisÃ©e.

**DerniÃ¨re mise Ã  jour:** 2025-11-08